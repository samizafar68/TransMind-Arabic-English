{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOXO3MpIEAvMMuAqHxe7jmf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvTXXsvKCvpB","executionInfo":{"status":"ok","timestamp":1741898518584,"user_tz":-300,"elapsed":2601352,"user":{"displayName":"Ahmad Hassan","userId":"07602843061636901323"}},"outputId":"f9eb0981-ada9-414e-e32a-93ca7fb7e178"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25, Loss: 4.7012\n","Epoch 2/25, Loss: 3.8479\n","Epoch 3/25, Loss: 3.6026\n","Epoch 4/25, Loss: 3.4234\n","Epoch 5/25, Loss: 3.2654\n","Epoch 6/25, Loss: 3.1249\n","Epoch 7/25, Loss: 2.9963\n","Epoch 8/25, Loss: 2.8710\n","Epoch 9/25, Loss: 2.7541\n","Epoch 10/25, Loss: 2.6421\n","Epoch 11/25, Loss: 2.5335\n","Epoch 12/25, Loss: 2.4341\n","Epoch 13/25, Loss: 2.3351\n","Epoch 14/25, Loss: 2.2385\n","Epoch 15/25, Loss: 2.1523\n","Epoch 16/25, Loss: 2.0627\n","Epoch 17/25, Loss: 1.9861\n","Epoch 18/25, Loss: 1.9121\n","Epoch 19/25, Loss: 1.8364\n","Epoch 20/25, Loss: 1.7673\n","Epoch 21/25, Loss: 1.7031\n","Epoch 22/25, Loss: 1.6413\n","Epoch 23/25, Loss: 1.5811\n","Epoch 24/25, Loss: 1.5270\n","Epoch 25/25, Loss: 1.4761\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-b0913186906d>:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"transformer_ara_eng_custom_tokenizer.pth\", map_location=device))\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n","  output = torch._nested_tensor_from_mask(\n"]},{"output_type":"stream","name":"stdout","text":["Source: Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…\n","Translated: correct the windows , if you are all children .\n"]}],"source":["# ============================\n","# ğŸ”¹ 1. Install Required Libraries\n","# ============================\n","#!pip install torch datasets\n","\n","# ============================\n","# ğŸ”¹ 2. Import Libraries\n","# ============================\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from datasets import load_dataset, concatenate_datasets\n","from torch.utils.data import DataLoader\n","import os\n","import re\n","import math\n","from collections import Counter\n","from torch.nn.utils.rnn import pad_sequence\n","import json\n","\n","# ============================\n","# ğŸ”¹ 3. Load Dataset (Arabic-English)\n","# ============================\n","dataset = load_dataset(\"Helsinki-NLP/tatoeba_mt\", \"ara-eng\")\n","train_data = dataset['validation']  # Use validation set for training\n","test_data = dataset['test']  # Use test set for additional training\n","\n","# Combine validation and test datasets\n","combined_data = concatenate_datasets([train_data, test_data])\n","\n","# ============================\n","# ğŸ”¹ 4. Build Custom Tokenizer\n","# ============================\n","class CustomTokenizer:\n","    def __init__(self):\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab_size = 0\n","        self.special_tokens = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n","\n","    def build_vocab(self, texts):\n","        \"\"\"Build vocabulary from a list of texts.\"\"\"\n","        all_words = Counter()\n","        for text in texts:\n","            words = self.tokenize(text)\n","            all_words.update(words)\n","\n","        # Add special tokens first\n","        for token in self.special_tokens:\n","            self.word2idx[token] = self.vocab_size\n","            self.idx2word[self.vocab_size] = token\n","            self.vocab_size += 1\n","\n","        # Add other words\n","        for word, _ in all_words.most_common():\n","            if word not in self.word2idx:\n","                self.word2idx[word] = self.vocab_size\n","                self.idx2word[self.vocab_size] = word\n","                self.vocab_size += 1\n","\n","    def tokenize(self, text):\n","        \"\"\"Tokenize text into words and punctuation.\"\"\"\n","        return re.findall(r'\\w+|[^\\w\\s]', text.lower())\n","\n","    def encode(self, text):\n","        \"\"\"Convert text to token IDs.\"\"\"\n","        tokens = self.tokenize(text)\n","        return [self.word2idx.get(token, self.word2idx[\"<unk>\"]) for token in tokens]\n","\n","    def decode(self, token_ids):\n","        \"\"\"Convert token IDs back to text.\"\"\"\n","        tokens = [self.idx2word.get(idx, \"<unk>\") for idx in token_ids]\n","        return \" \".join(tokens)\n","\n","    def save(self, filepath):\n","        \"\"\"Save tokenizer to a JSON file.\"\"\"\n","        tokenizer_dict = {\n","            \"word2idx\": self.word2idx,\n","            \"idx2word\": {int(k): v for k, v in self.idx2word.items()},\n","            \"vocab_size\": self.vocab_size,\n","            \"special_tokens\": self.special_tokens\n","        }\n","        with open(filepath, \"w\") as f:\n","            json.dump(tokenizer_dict, f)\n","\n","    def load(self, filepath):\n","        \"\"\"Load tokenizer from a JSON file.\"\"\"\n","        with open(filepath, \"r\") as f:\n","            tokenizer_dict = json.load(f)\n","        self.word2idx = tokenizer_dict[\"word2idx\"]\n","        self.idx2word = {int(k): v for k, v in tokenizer_dict[\"idx2word\"].items()}\n","        self.vocab_size = tokenizer_dict[\"vocab_size\"]\n","        self.special_tokens = tokenizer_dict[\"special_tokens\"]\n","\n","# Build the tokenizer\n","tokenizer = CustomTokenizer()\n","all_texts = [example['sourceString'] for example in combined_data] + [example['targetString'] for example in combined_data]\n","tokenizer.build_vocab(all_texts)\n","\n","# Save the tokenizer\n","tokenizer.save(\"tokenizer.json\")\n","\n","# Define special token IDs\n","PAD_TOKEN_ID = tokenizer.word2idx[\"<pad>\"]\n","SOS_TOKEN_ID = tokenizer.word2idx[\"<sos>\"]\n","EOS_TOKEN_ID = tokenizer.word2idx[\"<eos>\"]\n","UNK_TOKEN_ID = tokenizer.word2idx[\"<unk>\"]\n","\n","# ============================\n","# ğŸ”¹ 5. Preprocess Data (Tokenization)\n","# ============================\n","def preprocess_data(example):\n","    source_text = example['sourceString']\n","    target_text = example['targetString']\n","    source_tokens = [SOS_TOKEN_ID] + tokenizer.encode(source_text) + [EOS_TOKEN_ID]  # Add <sos> and <eos>\n","    target_tokens = [SOS_TOKEN_ID] + tokenizer.encode(target_text) + [EOS_TOKEN_ID]  # Add <sos> and <eos>\n","    return {'source': source_tokens, 'target': target_tokens}\n","\n","# Preprocess the combined dataset\n","combined_data = combined_data.map(preprocess_data)\n","\n","# ============================\n","# ğŸ”¹ 6. Create DataLoader\n","# ============================\n","class TranslationDataset(data.Dataset):\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.dataset[idx]['source']), torch.tensor(self.dataset[idx]['target'])\n","\n","# Collate Function for Padding\n","def collate_fn(batch):\n","    sources, targets = zip(*batch)\n","    sources_padded = pad_sequence(sources, batch_first=True, padding_value=PAD_TOKEN_ID)\n","    targets_padded = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN_ID)\n","    return sources_padded, targets_padded\n","\n","# Create dataset and dataloader\n","dataset = TranslationDataset(combined_data)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","\n","# ============================\n","# ğŸ”¹ 7. Transformer Model\n","# ============================\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        self.pe = pe.unsqueeze(0)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1), :].to(x.device)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size):\n","        super(Transformer, self).__init__()\n","        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n","        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model)\n","\n","        self.transformer = nn.Transformer(d_model, num_heads, num_layers, num_layers, dff, batch_first=True)\n","        self.fc_out = nn.Linear(d_model, target_vocab_size)\n","\n","    def forward(self, src, tgt):\n","        src_emb = self.positional_encoding(self.encoder_embedding(src))\n","        tgt_emb = self.positional_encoding(self.decoder_embedding(tgt))\n","\n","        src_padding_mask = (src == PAD_TOKEN_ID)\n","        tgt_padding_mask = (tgt == PAD_TOKEN_ID)\n","        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n","\n","        transformer_out = self.transformer(\n","            src_emb, tgt_emb,\n","            src_key_padding_mask=src_padding_mask,\n","            tgt_key_padding_mask=tgt_padding_mask,\n","            tgt_mask=tgt_mask\n","        )\n","        return self.fc_out(transformer_out)\n","\n","# ============================\n","# ğŸ”¹ 8. Define Model & Training Setup\n","# ============================\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = Transformer(\n","    num_layers=6, d_model=256, num_heads=8, dff=1024,\n","    input_vocab_size=tokenizer.vocab_size, target_vocab_size=tokenizer.vocab_size\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n","\n","# ============================\n","# ğŸ”¹ 9. Training Loop\n","# ============================\n","def train_epoch(model, dataloader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for src, tgt in dataloader:\n","        src, tgt = src.to(device), tgt.to(device)\n","        optimizer.zero_grad()\n","        output = model(src, tgt[:, :-1])\n","        loss = criterion(output.view(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","num_epochs = 25  # Adjust as needed\n","for epoch in range(num_epochs):\n","    loss = train_epoch(model, dataloader, optimizer, criterion)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n","\n","# Save Model\n","torch.save(model.state_dict(), \"transformer_ara_eng_custom_tokenizer.pth\")\n","\n","# ============================\n","# ğŸ”¹ 10. Translation Function\n","# ============================\n","def translate(model, source_text, max_len=100):\n","    model.eval()\n","    with torch.no_grad():\n","        source_tokens = [SOS_TOKEN_ID] + tokenizer.encode(source_text) + [EOS_TOKEN_ID]\n","        source = torch.tensor([source_tokens]).to(device)\n","        target = torch.tensor([[SOS_TOKEN_ID]]).to(device)\n","\n","        for _ in range(max_len):\n","            output = model(source, target)\n","            next_token = output[:, -1, :].argmax(dim=-1).item()\n","            if next_token == EOS_TOKEN_ID:\n","                break\n","            target = torch.cat([target, torch.tensor([[next_token]]).to(device)], dim=1)\n","\n","        translated_text = tokenizer.decode(target[0].tolist())\n","        translated_text = translated_text.replace(\"<sos>\", \"\").replace(\"<eos>\", \"\").strip()\n","        return translated_text\n","\n","# Load and test the model\n","model.load_state_dict(torch.load(\"transformer_ara_eng_custom_tokenizer.pth\", map_location=device))\n","model.eval()\n","\n","# Example translation\n","source_text = \"Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…\"\n","translated_text = translate(model, source_text)\n","print(f\"Source: {source_text}\")\n","print(f\"Translated: {translated_text}\")"]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLvj1p0VC1jy","executionInfo":{"status":"ok","timestamp":1741895255872,"user_tz":-300,"elapsed":6268,"user":{"displayName":"Ahmad Hassan","userId":"07602843061636901323"}},"outputId":"e875358d-9e92-4ebb-d872-9b382d63e9bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["def translate(model, source_text, max_len=100):\n","    model.eval()\n","    with torch.no_grad():\n","        source_tokens = [SOS_TOKEN_ID] + tokenizer.encode(source_text) + [EOS_TOKEN_ID]\n","        source = torch.tensor([source_tokens]).to(device)\n","        target = torch.tensor([[SOS_TOKEN_ID]]).to(device)\n","\n","        for _ in range(max_len):\n","            output = model(source, target)\n","            next_token = output[:, -1, :].argmax(dim=-1).item()\n","            if next_token == EOS_TOKEN_ID:\n","                break\n","            target = torch.cat([target, torch.tensor([[next_token]]).to(device)], dim=1)\n","\n","        translated_text = tokenizer.decode(target[0].tolist())\n","        translated_text = translated_text.replace(\"<sos>\", \"\").replace(\"<eos>\", \"\").strip()\n","        return translated_text\n","\n","# Load and test the model\n","model.load_state_dict(torch.load(\"transformer_ara_eng_custom_tokenizer.pth\", map_location=device))\n","model.eval()\n","\n","# Example translation\n","source_text = \"Ø§Ù„Ø·Ù‚Ø³ Ø¬Ù…ÙŠÙ„ Ø§Ù„ÙŠÙˆÙ…\"\n","translated_text = translate(model, source_text)\n","print(f\"Source: {source_text}\")\n","print(f\"Translated: {translated_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-U6oWrubDC1i","executionInfo":{"status":"ok","timestamp":1741898971517,"user_tz":-300,"elapsed":318,"user":{"displayName":"Ahmad Hassan","userId":"07602843061636901323"}},"outputId":"91ac1cd1-31a4-49fc-ac2c-8b341cb70489"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-66c10546815d>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"transformer_ara_eng_custom_tokenizer.pth\", map_location=device))\n"]},{"output_type":"stream","name":"stdout","text":["Source: Ø§Ù„Ø·Ù‚Ø³ Ø¬Ù…ÙŠÙ„ Ø§Ù„ÙŠÙˆÙ…\n","Translated: the weather is beautiful day .\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Z-tsWfzwQP6I"},"execution_count":null,"outputs":[]}]}